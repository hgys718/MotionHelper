As a designer into motion, I chose to create an app that can help me with my process or anyone who are also into motion design. Motion Helper is a beginner-friendly Streamlit application designed to support motion graphic ideation by combining text and image inputs with pre-trained HuggingFace models. The app uses distilgpt2, a lightweight text-generation model, to generate creative motion directions based on a project’s title, mood, keywords, and written description. By structuring the prompt with clear contextual information, the model produces short, focused suggestions that emphasize motion design considerations such transitions and typography behavior. In addition, the app integrates Salesforce/blip-image-captioning-base, an image-to-text model, which generates a descriptive caption from an uploaded image. This caption is then used as input for the text-generation model, allowing the app to suggest which visual elements in a static image could be animated for motion graphics.

The application also incorporates a small CSV dataset of example motion prompts, loaded with Pandas, which provides reference material and helps ground the generated outputs. When a user selects a mood, the app retrieves and displays related examples from the dataset alongside the AI-generated results. Streamlit’s caching features are used to efficiently load both the dataset and the models, keeping the app responsive. Overall, the process focuses on clear prompt design, simple data usage, and an intuitive interface, demonstrating how pre-trained NLP and vision models can be combined in a practical, creative tool for motion graphics brainstorming.

Link to streamlit app: https://settings-42zgbsu5utngtl3gpzkmdj.streamlit.app/ 
